from pyspark.sql import SparkSession

#TSQ0lvxjWA6Y3S4bE6G5  BAD1QKX0QDIS1SO2
#QYhj55Ax47WD0y3I97BvKI7E5tkd6j3QEKnKsmeg  5QV2JFP3ZZHO0EYHGJ5KPB2AA4TMCU0G
#http://s3a-hl.s3a:9000
minio_endpoint = "http://minio:9000"  # Ensure this matches your setup
minio_access_key = "PgaxJFyCW63gJ1bkkgi7"
minio_secret_key = "H0kfxCNZHX0Smy0BK89TepzoiqzLkufkfpKNitpo"
minio_bucket = "test"

spark = SparkSession.builder \
    .appName("MinIOs") \
    .config('spark.master','spark://193193aba901:7077')\
    .config("spark.jars.packages", "org.apache.hadoop:hadoop-aws:3.3.4") \
    .config("spark.hadoop.fs.s3a.endpoint", minio_endpoint) \
    .config("spark.hadoop.fs.s3a.access.key", minio_access_key) \
    .config("spark.hadoop.fs.s3a.secret.key", minio_secret_key) \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
    .getOrCreate()



dataframe = spark.read.json('s3a://test/orders.json')

average = dataframe.agg({'amount':'avg'})

average.write.format("csv").option("header", "true").save("s3a://test/json/")

average.show()




df = spark.read.csv("s3a://test/taxi.csv")
df.show()
spark.stop()




